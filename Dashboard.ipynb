{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIY Disease Tracking Dashboard\n",
    "## COVID-19 healthcare occupied beds by day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following dashboard focuses on the metric 'COVID-19 healthcare occupied beds by day'. This shows the mean number of beds occupied by confirmed COVID-19 patients over the 7 days up to and including the dates shown.\n",
    "\n",
    "These statistics are important as understanding the rates and patterns of hospital admissions can help to inform planning around hospital pressures including beds and staffing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import ipywidgets as wdg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# make figures larger\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology of the data\n",
    "\n",
    "This data includes people admitted to hospital who tested positive for COVID-19 in the 14 days before their admission and during their stay. Hospital inpatients who are diagnosed with COVID-19 after admission are reported as being admitted on the day before their diagnosis. Admissions figures include people admitted to NHS acute hospitals and mental health and learning disability (MHLD) trusts.\n",
    "\n",
    "Updates are published by NHS England on the second Thursday of each month, and contain data up to the end of the previous month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON files and store the raw data in some variable. Edit as appropriate\n",
    "# Create jsondata variable as dictionary\n",
    "jsondata = {}\n",
    "# Load the JSON file from disk into jsondata\n",
    "with open(\"beds.json\", \"rt\") as INFILE:\n",
    "    jsondata = json.load(INFILE)\n",
    "# print(jsondata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-01 00:00:00  to  2024-10-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Copy in function for parse_date\n",
    "def parse_date(datestring):\n",
    "    \"\"\" Convert a date string into a pandas datetime object \"\"\"\n",
    "    return pd.to_datetime(datestring, format=\"%Y-%m-%d\")\n",
    "# Create function to wrangle the data\n",
    "def wrangle_data(jsondata):\n",
    "    \"\"\" Parameters: rawdata - data from json file or API call. Returns a dataframe.\n",
    "    Edit to include the code that wrangles the data, creates the dataframe and fills it in. \"\"\"\n",
    "    # Extract first 5 elements from jsondata\n",
    "    jsondata[:5]\n",
    "\n",
    "    # Retrieve the values from the data slice and sort into a dictionary with the dates as keys and desired metrics as the values\n",
    "    data = {}\n",
    "    for dataset in [jsondata]:\n",
    "        for entry in dataset:\n",
    "            date = entry['date']\n",
    "            metric = entry['metric']\n",
    "            value = entry['metric_value']\n",
    "            if date not in data:\n",
    "                data[date]= {}\n",
    "            data[date][metric] = value\n",
    "    \n",
    "    # Extract all the dates from data and sort them\n",
    "    dates = list(data.keys())\n",
    "    dates.sort()\n",
    "    dates\n",
    "\n",
    "    # Using function parse_date find and print the first and last date for the data set\n",
    "    startdate = parse_date(dates[0])\n",
    "    enddate = parse_date(dates[-1])\n",
    "    print (startdate, ' to ', enddate)\n",
    "\n",
    "    # Turn the data into a data frame\n",
    "    # Create an index as a date_range: this is the date analog of a range for integers, and it will include any dates that may be missing from our list.\n",
    "    index = pd.date_range(startdate, enddate, freq='D')\n",
    "\n",
    "    # Define the DateFrame by specifying its index and the title of its columns.\n",
    "    timeseriesdfbeds = pd.DataFrame(index=index, columns=['beds'])\n",
    "\n",
    "    # Fill DataFrame with values from COVID-19 healthcare occupied beds by day\n",
    "    # Translate the columns to metrics\n",
    "    metrics = {'beds': 'COVID-19_healthcare_occupiedBedsByDay'}\n",
    "    for date, entry in data.items(): # each entry is a dictionary with beds\n",
    "        pd_date = parse_date(date) # convert to Pandas format\n",
    "        for column in ['beds']: \n",
    "            metric_name = metrics[column]\n",
    "            # Do not assume all values are there for every date - if a value is not available, insert a 0.0\n",
    "            value = entry.get(metric_name, 0.0)\n",
    "            # Access a specific location in the dataframe - use .loc and put index, column in a single set of [ ]\n",
    "            timeseriesdfbeds.loc[date, column] = value\n",
    "                \n",
    "    # Fill in any remaining null values due to missing dates\n",
    "    timeseriesdfbeds.fillna(0.0, inplace=True)\n",
    "    # Return the final DataFrame        \n",
    "    return timeseriesdfbeds\n",
    "\n",
    "# putting the wrangling code into a function allows you to call it again after refreshing the data through \n",
    "# the API. You should call the function directly on the JSON data when the dashboard starts, by including \n",
    "# the call in this cell as below:\n",
    "df = wrangle_data(jsondata) # df is the dataframe for plotting\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download current data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you desire to view different data based on the metric please click Fetch Data button below.\n",
    "\n",
    "This will generate more data and refresh the graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create APIwrapper class to build the endpoint from the structure and handle the paging\n",
    "class APIwrapper:\n",
    "    # class variables shared among all instances\n",
    "    _access_point=\"https://api.ukhsa-dashboard.data.gov.uk\"\n",
    "    _last_access=0.0 # time of last api access\n",
    "    \n",
    "    def __init__(self, theme, sub_theme, topic, geography_type, geography, metric):\n",
    "        \"\"\" Init the APIwrapper object, constructing the endpoint from the structure\n",
    "        parameters \"\"\"\n",
    "        # build the path with all the required structure parameters. You do not need to edit this line,\n",
    "        # parameters will be replaced by the actual values when you instantiate an object of the class!\n",
    "        url_path=(f\"/themes/{theme}/sub_themes/{sub_theme}/topics/{topic}/geography_types/\" +\n",
    "                  f\"{geography_type}/geographies/{geography}/metrics/{metric}\")\n",
    "        # our starting API endpoint\n",
    "        self._start_url=APIwrapper._access_point+url_path\n",
    "        self._filters=None\n",
    "        self._page_size=-1\n",
    "        # will contain the number of items\n",
    "        self.count=None\n",
    "\n",
    "    def get_page(self, filters={}, page_size=5):\n",
    "        \"\"\" Access the API and download the next page of data. Sets the count\n",
    "        attribute to the total number of items available for this query. Changing\n",
    "        filters or page_size will cause get_page to restart from page 1. Rate\n",
    "        limited to three request per second. The page_size parameter sets the number\n",
    "        of data points in one response page (maximum 365); use the default value \n",
    "        for debugging your structure and filters. \"\"\"\n",
    "        # Check page size is within range\n",
    "        if page_size>365:\n",
    "            raise ValueError(\"Max supported page size is 365\")\n",
    "        # restart from first page if page or filters have changed\n",
    "        if filters!=self._filters or page_size!=self._page_size:\n",
    "            self._filters=filters\n",
    "            self._page_size=page_size\n",
    "            self._next_url=self._start_url\n",
    "        # signal the end of data condition\n",
    "        if self._next_url==None: \n",
    "            return [] # we already fetched the last page\n",
    "        # simple rate limiting to avoid bans\n",
    "        curr_time=time.time() # Unix time: number of seconds since the Epoch\n",
    "        deltat=curr_time-APIwrapper._last_access\n",
    "        if deltat<0.33: # max 3 requests/second\n",
    "            time.sleep(0.33-deltat)\n",
    "        APIwrapper._last_access=curr_time\n",
    "        # build parameter dictionary by removing all the None\n",
    "        # values from filters and adding page_size\n",
    "        parameters={x: y for x, y in filters.items() if y!=None}\n",
    "        parameters['page_size']=page_size\n",
    "        # the page parameter is already included in _next_url.\n",
    "        # This is the API access. Response is a dictionary with various keys.\n",
    "        # the .json() method decodes the response into Python object (dictionaries,\n",
    "        # lists; 'null' values are translated as None).\n",
    "        response = requests.get(self._next_url, params=parameters).json()\n",
    "        # update url so we'll fetch the next page\n",
    "        self._next_url=response['next']\n",
    "        self.count=response['count']\n",
    "        # data are in the nested 'results' list\n",
    "        return response['results'] \n",
    "\n",
    "    def get_all_pages(self, filters={}, page_size=365):\n",
    "        \"\"\" Access the API and download all available data pages of data. Sets the count\n",
    "        attribute to the total number of items available for this query. API access rate\n",
    "        limited to three request per second. The page_size parameter sets the number\n",
    "        of data points in one response page (maximum 365), and controls the trade-off\n",
    "        between time to load a page and number of pages; the default should work well \n",
    "        in most cases. The number of items returned should in any case be equal to \n",
    "        the count attribute. \"\"\"\n",
    "        data=[] # build up all data here\n",
    "        while True:\n",
    "            # use get_page to do the job, including the pacing\n",
    "            next_page=self.get_page(filters, page_size)\n",
    "            if next_page==[]:\n",
    "                break # we are done\n",
    "            data.extend(next_page)\n",
    "        return data\n",
    "    \n",
    "# Place your API access code in this function. Do not call this function directly; it will be called by \n",
    "# the button callback. \n",
    "def access_api():\n",
    "    \"\"\" Accesses the UKHSA API. Return data as a like-for-like replacement for the \"canned\" data loaded from the JSON file. \"\"\"\n",
    "    # Define the structure of the query\n",
    "    structure = {\"theme\": \"infectious_disease\", \n",
    "            \"sub_theme\": \"respiratory\",\n",
    "            \"topic\": \"COVID-19\",\n",
    "            \"geography_type\": \"Nation\", \n",
    "            \"geography\": \"England\", \n",
    "            \"metric\": \"COVID-19_healthcare_occupiedBedsByDay\",}\n",
    "    try:\n",
    "        api = APIwrapper(**structure)\n",
    "        beds = api.get_all_pages()\n",
    "        print(f\"Total data points retrieved: {len(beds)}\")\n",
    "        \n",
    "        # Save downloaded data to a JSON file\n",
    "        with open(\"beds.json\", \"wt\") as OUTF:\n",
    "            json.dump(beds, OUTF)\n",
    "        print(\"Data saved to 'beds.json' successfully.\")\n",
    "\n",
    "        return beds\n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing the API: {e}\")\n",
    "        return {} # return data read from the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a76d8d59489d4076b9380fbfefb35d64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='warning', description='Fetch Data', icon='download', style=ButtonStyle(), tooltip='Fetch …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing data from the API...\n",
      "Total data points retrieved: 1553\n",
      "Data saved to 'beds.json' successfully.\n",
      "Wrangling the data...\n",
      "2020-08-01 00:00:00  to  2024-10-31 00:00:00\n",
      "Graph refreshed!\n"
     ]
    }
   ],
   "source": [
    "# Printout from this function will be lost in Voila unless captured in an\n",
    "# output widget - therefore, we give feedback to the user by changing the \n",
    "# appearance of the button\n",
    "# Create function to refresh the graph\n",
    "def refresh_graph():\n",
    "    print(\"Graph refreshed!\")\n",
    "\n",
    "def api_button_callback(button):\n",
    "    \"\"\" Button callback - it must take the button as its parameter (unused in this case).\n",
    "    Accesses API, wrangles data, updates global variable df used for plotting. \"\"\"\n",
    "    # Get fresh data from the API. If you have time, include some error handling\n",
    "    # around this call.\n",
    "    # wrangle the data and overwrite the dataframe for plotting\n",
    "    global df\n",
    "    try:\n",
    "        print(\"Accessing data from the API...\")\n",
    "        apidata = access_api() # Fetching data from API\n",
    "        if apidata:\n",
    "            print(\"Wrangling the data...\")\n",
    "            df = wrangle_data(apidata) # Wrangle and update the global DataFrame\n",
    "        # the graph won't refresh until the user interacts with the widget.\n",
    "        # this function simulates the interaction, see Graph and Analysis below.\n",
    "        # The function needs to be adapted to your graph; you can omit this call\n",
    "        # in the first instance\n",
    "            refresh_graph() # Force graph refresh\n",
    "            # after all is done, you can switch the icon on the button to a \"check\" sign\n",
    "            # and optionally disable the button - it won't be needed again. If you are \n",
    "            # implementing error handling, you can use icons \"unlink\" or \"times\" and \n",
    "            # change the button text to \"Unavailable\" when the api call fails.\n",
    "            apibutton.icon = \"check\"\n",
    "            apibutton.tooltip = \"Data refreshed!\"\n",
    "        else:\n",
    "            apibutton.icon = \"Unavailable\"\n",
    "            apibutton.tooltip = \"API call failed. Please try again\"\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        apibutton.icon = \"times\"\n",
    "        apibutton.tooltip = \"Error occurred. Check the logs\"\n",
    "\n",
    "# Define the refresh button   \n",
    "apibutton = wdg.Button(\n",
    "    description='Fetch Data', \n",
    "    disabled = False,\n",
    "    button_style = 'warning', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip = \"Fetch fresh data from the API\",\n",
    "    # FontAwesome names without the `fa-` prefix - try \"download\"\n",
    "    icon = 'download'\n",
    ")\n",
    "\n",
    "# remember to register your button callback function with the button\n",
    "apibutton.on_click(api_button_callback) # the name of your function inside these brackets\n",
    "# Display button \n",
    "display(apibutton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphs and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These graphs give a visual representation on the COVID-19 healthcare occupied beds by day metric between the dates 08/01/2020 to 31/10/2024.\n",
    "\n",
    "1.\tGraph 1 (Linear Scale):\n",
    "\n",
    "- This graph shows the daily number of hospital beds occupied by confirmed COVID-19 cases over time on a   linear scale.\n",
    "\n",
    "- Key features:\n",
    "\t - A peak in occupied beds around early 2021, which corresponds to the significant wave of COVID-19 cases during that period.\n",
    "\t - Subsequent smaller waves in 2022 and a noticeable decline in 2023 and 2024.\n",
    "        \n",
    "2.\tGraph 2 (Logarithmic Scale):\n",
    "\n",
    "- This graph displays the same data but on a logarithmic scale, which is particularly useful for analyzing changes over time when values vary widely.\n",
    "\n",
    "- Key features:\n",
    "     - The logarithmic scale highlights proportional changes, making smaller fluctuations in bed occupancy more visible, especially during periods with fewer cases.\n",
    "\t - While the peaks align with the first graph, the visualization helps emphasize gradual trends in decline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cee45204532147a2bdb6c91c8cda2134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(SelectMultiple(description='Stats:', index=(0,), options=('beds',), rows=1, value=('beds',)), R…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f496508c6b7f49fd8ff2572a3ee73eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instructions:\n",
      "1. Use the 'Stats' selector to choose one or more data series to display.\n",
      "2. Use the 'Scale' selector to switch between linear and logarithmic scale.\n",
      "3. The graph will update automatically when selections are changed.\n"
     ]
    }
   ],
   "source": [
    "# Load pickle file containing DataFrame for occupied beds of confirmed COVID-19 cases\n",
    "timeseriesdfbeds = pd.read_pickle(\"timeseriesdfbeds.pkl\")\n",
    "\n",
    "# Create SelectMultiple widget for selecting data series (only beds is available)\n",
    "series = wdg.SelectMultiple(\n",
    "    options=['beds'], # Available options for selection\n",
    "    value=['beds'], # Default value\n",
    "    rows=1, # Number of visible rows\n",
    "    description='Stats:',\n",
    "    disabled=False\n",
    ")\n",
    "# Create RadioButtons widget for selecting the scale type (linear/logarithmic)\n",
    "scale = wdg.RadioButtons(\n",
    "    options=['linear', 'log'],\n",
    "#   layout={'width': 'max-content'}, # If the items' names are long\n",
    "    description='Scale:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Group widgets into a horizontal box (HBox) layout \n",
    "controls = wdg.HBox([series, scale])\n",
    "\n",
    "# Define function to plot the time series graph based on selected options\n",
    "def timeseries_graph(gcols, gscale):\n",
    "   # Determine if the y-axis should be logarithmic\n",
    "    logscale = gscale == 'log'\n",
    "    \n",
    "    # Check the number of columns selected\n",
    "    ncols = len(gcols)\n",
    "    if ncols > 0:\n",
    "        try:\n",
    "            # Plot the selected columns with the appropriate scale\n",
    "            timeseriesdfbeds[list(gcols)].plot(logy=logscale)\n",
    "            # df[list(gcols)].plot(logy=logscale) # Use updated DataFrame once refresh button has been activated\n",
    "            plt.xlabel(\"Date\")  # Label for the x-axis\n",
    "            plt.ylabel(\"Occupied Beds\")  # Label for the y-axis\n",
    "            plt.title(\"Occupied Beds of Confirmed COVID-19 Cases\")  # Graph title\n",
    "            plt.legend(title=\"Stats\")  # Add a legend with a title\n",
    "            plt.show()  # Display the graph\n",
    "        except KeyError:\n",
    "            # Handle the case where the selected columns are not found in the DataFrame\n",
    "            print(f\"Error: Columns {gcols} not found in DataFrame.\")\n",
    "    else:\n",
    "        # Provide instructions if no data is selected for plotting\n",
    "        print(\"Please select one data series to plot.\")\n",
    "\n",
    "def refresh_graph():\n",
    "    \"\"\" We change the value of the widget in order to force a redraw of the graph;\n",
    "    this is useful when the data have been updated. This is a bit of a gimmick; it\n",
    "    needs to be customised for one of your widgets. \"\"\"\n",
    "    current_selection = series.value\n",
    "    # Toggle the selection to force redraw\n",
    "    if current_selection:\n",
    "        series.value = []  # Clear selection temporarily\n",
    "        series.value = current_selection  # Reset to the original selection\n",
    "\n",
    "# Keep calling timeseries_graph(gcols=value_of_series, gscale=value_of_scale); \n",
    "# Capture output in widget graph   \n",
    "graph = wdg.interactive_output(timeseries_graph, {'gcols': series, 'gscale': scale})\n",
    "\n",
    "# Output widget controls with their respective graphs\n",
    "display(controls, graph)\n",
    "\n",
    "# Provide user instructions\n",
    "print(\"Instructions:\")\n",
    "print(\"1. Use the 'Stats' selector to choose one or more data series to display.\")\n",
    "print(\"2. Use the 'Scale' selector to switch between linear and logarithmic scale.\")\n",
    "print(\"3. The graph will update automatically when selections are changed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author and License** \n",
    "\n",
    "\"Based on UK Government [data](https://ukhsa-dashboard.data.gov.uk/) published by the [UK Health Security Agency](https://www.gov.uk/government/organisations/uk-health-security-agency) and on the [DIY Disease Tracking Dashboard Kit](https://github.com/fsmeraldi/diy-covid19dash) by Fabrizio Smeraldi. Released under the [GNU GPLv3.0 or later](https://www.gnu.org/licenses/).\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
